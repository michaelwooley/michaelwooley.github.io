<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computation on Michael Wooley&#39;s Homepage</title>
    <link>https://michaelwooley.github.io/categories/computation/</link>
    <description>Recent content in Computation on Michael Wooley&#39;s Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Aug 2018 18:28:59 -0400</lastBuildDate>
    <atom:link href="https://michaelwooley.github.io/categories/computation/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Time- and Memory-Efficient Solution to $\text{cholesky}\left[A\otimes B\right]\varepsilon$</title>
      <link>https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/</link>
      <pubDate>Mon, 20 Aug 2018 18:28:59 -0400</pubDate>
      
      <guid>https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/</guid>
      <description>

&lt;p&gt;This post discusses an efficient solution to $\text{cholesky}\left[A\otimes B\right]\varepsilon$, where $A$ and $B$ are real, symmetric, positive definite matrices of while $\varepsilon$ is an appropriately-sized vector. Why woul anyone ever want to compute this thing? Basically, an expression like this is going to pop up if you want to sample from a multivariate normal distribution with covariance matrix $A\otimes B$.&lt;/p&gt;

&lt;figure&gt;
&lt;label for=&#34;size-of0&#34; class=&#34;margin-toggle&#34;&gt;&amp;#8853;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;size-of0&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;span class=&#34;marginnote&#34;&gt;
    &lt;img src=&#34;https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/media/chol_kron_ab_size.svg&#34;&gt;
    We&amp;rsquo;ll quickly run into memory errors if we blindly compute $A\otimes B$. The projected matrix size in gigabytes assumes a 64-bit float.
&lt;/span&gt;
&lt;/figure&gt;


&lt;p&gt;For me, this expression arose as a bottleneck in a project that I&amp;rsquo;m working on that involves a Bayesian VAR with a Normal-Inverse-Wishart prior. What&amp;rsquo;s wrong with using regular NumPy to compute &lt;code&gt;np.linalg.cholesky(np.kron(A, B)).dot(e)&lt;/code&gt;? This matrix gets very big very fast. You can see this in Figure &lt;strong&gt;&lt;em&gt;INFS&lt;/em&gt;&lt;/strong&gt;, which considers the BVAR case with a set number of lags and $n$ variables per period. In the normal-inverse-wishart case the posterior covariance matrix has size $n(n\cdot lags+1)\times n(n\cdot lags+1)$. The right figure says that we need about 10,000 &lt;em&gt;gigabytes&lt;/em&gt; to compute $A\otimes B$ when $n=200$ and $lags=13$. I want to be able to accommodate specifications of this magnitude. In order to do so, though, I&amp;rsquo;m going to need to find an alternative to &lt;code&gt;np.linalg.cholesky(np.kron(A, B)).dot(e)&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;a-solution:a1555d59ae587cdf813d543d9fa6acc1&#34;&gt;A Solution&lt;/h2&gt;

&lt;p&gt;The key to solving this problem is to avoid explicitly computing $A \otimes B$. This can be done by observing that
$$\text{cholesky}\left[ A\otimes B\right] = \text{cholesky}[A]\otimes \text{cholesky}[B].$$
Let&amp;rsquo;s prove this. Recall that the Cholesky decomposition of a real, symmetric, positive definite matrix $X$ is a lower-triangular matrix $L$ such that:&lt;label for=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle sidenote-number&#34;&gt;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;span class=&#34;sidenote&#34;&gt;Cholesky decompositions can exist in other cases but we are only interested in this case. Note also that a Cholesky decomposition always exists when a matrix satisfies the properties on $X$&lt;/span&gt; 

$$X = LL^{\prime}$$
Now define $L_A$ and $L_B$ so that $A = L_A L_A^{\prime}$ and $B = L_B L_B^{\prime}$. Additionally define $L_C := L_A \otimes L_B$. Notice that $L_C$ is also lower-triangular and&amp;ndash;since $L_A$ and $L_B$ have real and postive diagonal entries&amp;ndash;so too does $L_C$. Consider the following:
$$
L_C L_C^{\prime} = (L_A \otimes L_B)(L_A \otimes L_B)^{\prime}=(L_A \otimes L_B)(L_A^{\prime} \otimes L_B^{\prime}) =(L_A L_A^{\prime} \otimes L_B L_B^{\prime})=A\otimes B
$$
From this we see that $L_C$ is the Cholesky decomposition of $A\otimes B$.&lt;/p&gt;

&lt;p&gt;What does this fact give us? In short, we can avoid explicitly computing the full kronecker product and instead multiply term-by-term.&lt;/p&gt;

&lt;p&gt;Here is some pseudo-code for the solution to $\text{cholesky}\left[A\otimes B\right]\varepsilon$:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #f8f8f8&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #0000FF&#34;&gt;chol_kron_ab_e&lt;/span&gt;(A: FMATRIX, B: FMATRIX, e: FVECTOR) &lt;span style=&#34;color: #666666&#34;&gt;-&amp;gt;&lt;/span&gt; FVECTOR:
  &lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;Solution to `cholesky[kron[A, B]] * e`.&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;  Args:&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;      A (FMATRIX): Real, Symmetric, Positive Definite Matrix of size [mA, mA]&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;      B (FMATRIX): Real, Symmetric, Positive Definite Matrix of size [mB, mB]&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;      e (FVECTOR): Vector of shape [mA * mB, 1]&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;  Returns:&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;      FVECTOR: Vector of shape [mA * mB, 1] solution to `cholesky[kron[A, B]] * e`&lt;/span&gt;
&lt;span style=&#34;color: #BA2121; font-style: italic&#34;&gt;  &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
  mA &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; A&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;]
  mB &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; B&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color: #666666&#34;&gt;0&lt;/span&gt;]
  L_a &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; cholesky(A)
  L_b &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; cholesky(B)

  out &lt;span style=&#34;color: #666666&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #666666&#34;&gt;.&lt;/span&gt;zeros((mA &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; mB))

  &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; ii &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;range&lt;/span&gt;(mA):
    &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; jj &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;range&lt;/span&gt;(ii &lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;):
      &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; hh &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;range&lt;/span&gt;(mB):
        &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;for&lt;/span&gt; kk &lt;span style=&#34;color: #AA22FF; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #008000&#34;&gt;range&lt;/span&gt;(hh &lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #666666&#34;&gt;1&lt;/span&gt;):
          out[mB &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; ii &lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt; hh] &lt;span style=&#34;color: #666666&#34;&gt;+=&lt;/span&gt; L_a[ii, jj] &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; L_b[hh, kk] &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; e[mB &lt;span style=&#34;color: #666666&#34;&gt;*&lt;/span&gt; jj &lt;span style=&#34;color: #666666&#34;&gt;+&lt;/span&gt; kk]

  &lt;span style=&#34;color: #008000; font-weight: bold&#34;&gt;return&lt;/span&gt; out
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Obviously, this would be pretty slow to run in standard python. In the tested implementation we used &lt;a href=&#34;https://numba.pydata.org/&#34;&gt;Numba&lt;/a&gt;, which can do explicit loops efficiently.&lt;label for=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle sidenote-number&#34;&gt;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;span class=&#34;sidenote&#34;&gt;For the sake of comparison, all of the test functions below are compiled with Numba.&lt;/span&gt; 
&lt;/p&gt;

&lt;h2 id=&#34;evaluation:a1555d59ae587cdf813d543d9fa6acc1&#34;&gt;Evaluation&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s see how well this thing works. Throughout, we&amp;rsquo;ll use a numba version of &lt;code&gt;np.linalg.cholesky(np.kron(A, B)).dot(e)&lt;/code&gt; as a benchmark.&lt;/p&gt;

&lt;p&gt;Figure &lt;em&gt;&lt;strong&gt;Whasfsa&lt;/strong&gt;&lt;/em&gt; provides some information on time-to-compute. I&amp;rsquo;ve kept the size of atrices relatively small so that the benchmark can be computed.&lt;/p&gt;

&lt;figure&gt;
&lt;label for=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;&gt;&amp;#8853;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;img src=&#34;https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/media/chol_kron_time_usage.svg&#34;&gt;
&lt;span class=&#34;marginnote&#34;&gt;The proposed algorith (&amp;ldquo;Loop&amp;rdquo;) provides a considerable speed-up over the benchmark and is pretty fast in absolute terms.&lt;/span&gt;
&lt;/figure&gt;


&lt;p&gt;From the left figure we see that the proposed algorithm quickly achieves a speed-up of greater than 100%. As the size of the matrices increase the speed-up increases at a concave/log-esque rate.&lt;/p&gt;

&lt;p&gt;The left figure plots the absolute time-to-compute for the proposed algorithm in seconds. Not surprisingly, this relationship is convex at all lags. However, in absolute terms it is still pretty fast.&lt;/p&gt;

&lt;p&gt;Figure &lt;em&gt;&lt;strong&gt;SAFSAFAS&lt;/strong&gt;&lt;/em&gt; compares the memory requirements of the two algorithms. Due to the long time-to-compute memory usage, we only did this at a few values. The memory usage statistic presented here is the maximum memory usage required by the process, as computed by the Jupyter Notebook magic &lt;a href=&#34;https://github.com/pythonprofilers/memory_profiler&#34;&gt;&lt;code&gt;%memit&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;
&lt;label for=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;&gt;&amp;#8853;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;img src=&#34;https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/media/chol_kron_memory_usage.svg&#34;&gt;
&lt;span class=&#34;marginnote&#34;&gt;Relative and Absolute Memory Usage.&lt;/span&gt;
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;The proposed algorithm is pretty memory-efficient. With 42 variables the NumPy method already requires 8.3 gigs of memory. Most people don&amp;rsquo;t have that kind of memory to spare!&lt;label for=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle sidenote-number&#34;&gt;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;span class=&#34;sidenote&#34;&gt;Based on the first figure, one might think that the NumPy method should require about a gig of memory. &lt;em&gt;&lt;strong&gt;WHY DOESN&amp;rsquo;T IT???&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt; 
 On the other hand, memory consumption of the alternative method is pretty much flat.&lt;label for=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle sidenote-number&#34;&gt;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;error: cannot access positional params by string name&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;span class=&#34;sidenote&#34;&gt;I believe that the seeming-drop in memory consumption in the last phase is coming from the fact that the memory profiler caught the function at an odd time. Alternatively, it could have to do with NumPy memory blocks? &lt;em&gt;&lt;strong&gt;WHY IS IT FLAT???&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt; 
&lt;/p&gt;

&lt;p&gt;Finally, we test the proposed algorithm for large-dimensional cases.&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;
&lt;label for=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;&gt;&amp;#8853;&lt;/label&gt;
&lt;input type=&#34;checkbox&#34; id=&#34;time-to-compute&#34; class=&#34;margin-toggle&#34;/&gt;
&lt;img src=&#34;https://michaelwooley.github.io/posts/solve-chol-kron-ab-e/media/chol_kron_big.svg&#34;&gt;
&lt;span class=&#34;marginnote&#34;&gt;Time-to-compute and memory usage for proposed algorithm only.&lt;/span&gt;
&lt;/figure&gt;
&lt;/p&gt;

&lt;h2 id=&#34;conclusion:a1555d59ae587cdf813d543d9fa6acc1&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;TBD&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>